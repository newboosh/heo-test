"""Build cache system using SQLite for incremental tracking.

Tracks artifacts, their dependencies, and content hashes to enable
efficient incremental builds. Uses SHA-256 hashing and timestamps
for change detection.
"""

import sqlite3
import hashlib
from pathlib import Path
from typing import Dict, List, Optional, Set
from datetime import datetime


class BuildCache:
    """SQLite-based incremental build cache.

    Tracks:
    - Artifacts (files generated by components)
    - Dependencies (what sources each artifact depends on)
    - File hashes (SHA-256) for change detection
    - Timestamps for temporal ordering
    """

    def __init__(self, db_path: str = ".claude/intelligence/.cache.db"):
        """Initialize BuildCache with SQLite database.

        Args:
            db_path: Path to SQLite database file.
        """
        self.db_path = Path(db_path)
        self.db_path.parent.mkdir(parents=True, exist_ok=True)
        self.conn: Optional[sqlite3.Connection] = None
        self._init_db()

    def _init_db(self):
        """Initialize database schema on first use."""
        self.conn = sqlite3.connect(str(self.db_path))
        cursor = self.conn.cursor()

        # Artifacts table: track built components
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS artifacts (
                id INTEGER PRIMARY KEY,
                name TEXT UNIQUE NOT NULL,
                component TEXT NOT NULL,
                built_at TIMESTAMP NOT NULL,
                output_path TEXT
            )
        """)

        # Dependencies table: track what each artifact depends on
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS dependencies (
                id INTEGER PRIMARY KEY,
                artifact_id INTEGER NOT NULL,
                source_path TEXT NOT NULL,
                file_hash TEXT NOT NULL,
                FOREIGN KEY (artifact_id) REFERENCES artifacts(id),
                UNIQUE(artifact_id, source_path)
            )
        """)

        # File hashes table: cache file hashes for quick lookup
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS file_hashes (
                id INTEGER PRIMARY KEY,
                file_path TEXT UNIQUE NOT NULL,
                hash TEXT NOT NULL,
                computed_at TIMESTAMP NOT NULL
            )
        """)

        self.conn.commit()

    def mark_built(self, artifact_name: str, component: str,
                   dependencies: Dict[str, str], output_path: Optional[str] = None):
        """Mark an artifact as built with its dependencies.

        Args:
            artifact_name: Unique identifier for the artifact.
            component: Component that created this artifact.
            dependencies: Dict mapping source file paths to their hashes.
            output_path: Optional path to the output artifact file.
        """
        cursor = self.conn.cursor()

        # Get artifact ID if it exists to clean up dependencies
        cursor.execute("SELECT id FROM artifacts WHERE name = ?", (artifact_name,))
        existing = cursor.fetchone()

        # Remove old dependencies first if artifact exists
        if existing:
            cursor.execute("DELETE FROM dependencies WHERE artifact_id = ?", (existing[0],))

        # Remove old artifact
        cursor.execute("DELETE FROM artifacts WHERE name = ?", (artifact_name,))

        # Insert artifact
        cursor.execute("""
            INSERT INTO artifacts (name, component, built_at, output_path)
            VALUES (?, ?, ?, ?)
        """, (artifact_name, component, datetime.now(), output_path))

        artifact_id = cursor.lastrowid

        # Insert dependencies
        for source_path, file_hash in dependencies.items():
            cursor.execute("""
                INSERT INTO dependencies (artifact_id, source_path, file_hash)
                VALUES (?, ?, ?)
            """, (artifact_id, source_path, file_hash))

        self.conn.commit()

    def is_fresh(self, artifact_name: str, sources: Dict[str, str]) -> bool:
        """Check if an artifact is fresh (all dependencies unchanged).

        Args:
            artifact_name: Name of artifact to check.
            sources: Dict mapping source file paths to their current hashes.

        Returns:
            True if artifact exists and all dependencies match current hashes.
        """
        cursor = self.conn.cursor()

        # Check if artifact exists
        cursor.execute("SELECT id FROM artifacts WHERE name = ?", (artifact_name,))
        row = cursor.fetchone()
        if not row:
            return False

        artifact_id = row[0]

        # Get stored dependencies
        cursor.execute("""
            SELECT source_path, file_hash FROM dependencies
            WHERE artifact_id = ?
        """, (artifact_id,))

        stored_deps = {row[0]: row[1] for row in cursor.fetchall()}

        # Check if all current sources match stored hashes
        if set(stored_deps.keys()) != set(sources.keys()):
            return False

        for source_path, current_hash in sources.items():
            if stored_deps.get(source_path) != current_hash:
                return False

        return True

    def invalidate(self, artifact_name: str):
        """Invalidate an artifact, forcing rebuild.

        Args:
            artifact_name: Name of artifact to invalidate.
        """
        cursor = self.conn.cursor()
        # Get artifact ID first to delete dependencies
        cursor.execute("SELECT id FROM artifacts WHERE name = ?", (artifact_name,))
        row = cursor.fetchone()
        if row:
            cursor.execute("DELETE FROM dependencies WHERE artifact_id = ?", (row[0],))
        cursor.execute("DELETE FROM artifacts WHERE name = ?", (artifact_name,))
        self.conn.commit()

    def compute_file_hash(self, file_path: str) -> str:
        """Compute SHA-256 hash of a file.

        Uses cached hash if file hasn't been modified.

        Args:
            file_path: Path to file to hash.

        Returns:
            SHA-256 hash string.

        Raises:
            FileNotFoundError: If file doesn't exist.
        """
        path = Path(file_path)
        if not path.exists():
            raise FileNotFoundError(f"File not found: {file_path}")

        # Check cache
        cursor = self.conn.cursor()
        cursor.execute(
            "SELECT hash, computed_at FROM file_hashes WHERE file_path = ?",
            (file_path,)
        )
        row = cursor.fetchone()

        if row:
            stored_hash, computed_at = row
            # Check if file was modified after hash was computed
            file_mtime = datetime.fromtimestamp(path.stat().st_mtime)
            if computed_at and file_mtime <= datetime.fromisoformat(computed_at):
                return stored_hash
            # File modified, recompute hash below

        # Compute hash
        sha256 = hashlib.sha256()
        with open(path, 'rb') as f:
            for chunk in iter(lambda: f.read(4096), b''):
                sha256.update(chunk)

        file_hash = sha256.hexdigest()

        # Cache it
        cursor.execute("""
            INSERT OR REPLACE INTO file_hashes (file_path, hash, computed_at)
            VALUES (?, ?, ?)
        """, (file_path, file_hash, datetime.now()))
        self.conn.commit()

        return file_hash

    def clear(self):
        """Clear all cache entries."""
        cursor = self.conn.cursor()
        cursor.execute("DELETE FROM artifacts")
        cursor.execute("DELETE FROM dependencies")
        cursor.execute("DELETE FROM file_hashes")
        self.conn.commit()

    def close(self):
        """Close database connection."""
        if self.conn:
            self.conn.close()

    def __del__(self):
        """Ensure database is closed on deletion."""
        self.close()
